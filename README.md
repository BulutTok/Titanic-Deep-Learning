# Titanic Survival Prediction 

*A handsâ€‘on demonstration of an endâ€‘toâ€‘end deepâ€‘learning pipeline with the classic Titanic dataset.*

---

## Repository Contents

| Path                                 | Description                                                                                                                                                                                                                                                          |
| ------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Titanic_Survival_Prediction_.ipynb` | Jupyter notebook that downloads the raw data, performs feature engineering & preprocessing with **scikitâ€‘learn** pipelines, trains a small **TensorFlow/Keras** neuralâ€‘network classifier, and evaluates it with accuracy, confusionâ€‘matrix & classificationâ€‘report. |
| `datasets/`                          | Created automatically at first run; stores the CSV files fetched from the original dataset source.                                                                                                                                                                   |
| `environment.yml` *(optional)*       | Conda environment file you can create with `conda env export > environment.yml` once the project runs on your machine.                                                                                                                                               |

---

##  Quick Start

```bash
# 1ï¸âƒ£  Clone the repo
git clone https://github.com/<your-user>/titanic-survival-prediction.git
cd titanic-survival-prediction

# 2ï¸âƒ£  (Recommended) create an isolated environment
conda create -n titanic python=3.11
conda activate titanic

# 3ï¸âƒ£  Install requirements
pip install -r requirements.txt        # or see the list below

# 4ï¸âƒ£  Launch the notebook
jupyter lab Titanic_Survival_Prediction_.ipynb
```

The notebook is **fully selfâ€‘contained**: the first code cell downloads the Kaggleâ€‘style CSVs directly from AurÃ©lien GÃ©ronâ€™s public repository, so no manual data download is needed.

---

##  Requirements

| Package        | Tested Version |
| -------------- | -------------- |
| `python`       | â‰¥ 3.10         |
| `pandas`       | â‰¥ 2.2          |
| `numpy`        | â‰¥ 1.26         |
| `scikitâ€‘learn` | â‰¥ 1.4          |
| `tensorflow`   | â‰¥ 2.16         |
| `jupyterlab`   | â‰¥ 4.2          |

*Tip:* if you are new to Deep Learning and want a smaller install, swap `tensorflow` for `tensorflowâ€‘cpu`.

---

## Workflow Highlights

1. **Data loading** â€“ CSVs are read into Pandas DataFrames; `PassengerId` is set as index.
2. **Preâ€‘processing pipeline**

   * Numerical columns âŸ¶ `SimpleImputer(strategy="median")`
   * Categorical columns âŸ¶ `SimpleImputer(strategy="most_frequent") â†’ OneHotEncoder(handle_unknown="ignore")`
   * `ColumnTransformer` stitches everything together.
3. **Model** â€“ Sequential Keras NN

   * `Input` layer â†’ denseâ€‘ReLU â†’ denseâ€‘ReLU â†’ sigmoid output.
4. **Training & validation** â€“ 20â€¯% holdâ€‘out split.
5. **Evaluation** â€“ Confusion matrix & `classification_report` (precision / recall / F1).

Feel free to tweak the architecture or replace it with gradientâ€‘boosting, random forests, etc.â€”the preprocessing pipeline stays valid.

---

## ğŸ“Š Results

### Training run snapshot (40Â epochs)

```
accuracy:      0.8469    loss: 0.3748
val_accuracy: 0.7933    val_loss: 0.4359
```

### Validationâ€‘set performance (179 passengers)

|              | **Predictedâ€¯0** | **Predictedâ€¯1** |
| ------------ | --------------: | --------------: |
| **Actualâ€¯0** |         **102** |               8 |
| **Actualâ€¯1** |              29 |          **40** |

* **Overall accuracy:** **79.3â€¯%**
* **Class metrics**

  * *Did not surviveÂ (0)* â€“ precisionÂ 0.779, recallÂ 0.927, F1Â 0.846
  * *SurvivedÂ (1)* â€“ precisionÂ 0.833, recallÂ 0.580, F1Â 0.684
  * Macroâ€‘average F1Â 0.765

### Most informative features

`Sex_female`, `Pclass_3`, `Fare`, `Age`, `Embarked_S`
*(see the notebookâ€™s final section for permutationâ€‘importance & coefficient plots)*

---



##  Contributing

1. Fork the repo & create your feature branch (`git checkout -b feat/amazing-idea`)
2. Commit your changes (`git commit -m 'Add amazing idea'`)
3. Push to the branch (`git push origin feat/amazing-idea`)
4. Open a pull request

Please follow [**PEPÂ 8**](https://peps.python.org/pep-0008/) and include unit tests where reasonable.

---

##  License

Distributed under the **MIT License**.
See `LICENSE` file for more information.

---

### âœ¨ Acknowledgements

* Dataset originated from the **[Kaggle Titanic Challenge](https://www.kaggle.com/competitions/titanic)**.
* Download script points to the mirror hosted in the companion repo of *Handsâ€‘On Machine Learning with Scikitâ€‘Learn, Keras & TensorFlow* by **AurÃ©lien GÃ©ron**.


## Contact

For questions, suggestions, or contributions, please contact:

**Bulut Tok**  
Email: [buluttok2013@gmail.com]

